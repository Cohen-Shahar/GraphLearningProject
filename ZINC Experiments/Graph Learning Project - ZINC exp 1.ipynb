{"cells":[{"cell_type":"markdown","metadata":{"id":"XuXWJLEm2UWS"},"source":["# **Graph Learning Project - ZINC exp 1**"]},{"cell_type":"markdown","metadata":{"id":"8gzsP50bF6Gb"},"source":["By Shahar Cohen 205669260 & Alexander petrunin 205782568"]},{"cell_type":"markdown","metadata":{"id":"67gOQITlCNQi"},"source":["# Installation"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4714,"status":"ok","timestamp":1731744371956,"user":{"displayName":"שחר כהן","userId":"02544236883128860612"},"user_tz":-120},"id":"J_m9l6OYCQZP","outputId":"6912b8a7-ec33-4c25-af88-aedde59a9b9a"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m61.4/63.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/1.1 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install -q torch-geometric"]},{"cell_type":"markdown","source":["# SETUP"],"metadata":{"id":"9V_JqF8wNr1q"}},{"cell_type":"code","execution_count":35,"metadata":{"id":"PRfgbfTjCRD_","executionInfo":{"status":"ok","timestamp":1731748199533,"user_tz":-120,"elapsed":321,"user":{"displayName":"שחר כהן","userId":"02544236883128860612"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch_geometric.nn import GPSConv, GatedGraphConv, TransformerConv, GINEConv\n","from torch_geometric.data import Data\n","import torch.nn.functional as F\n","from torch_geometric.nn import global_mean_pool, global_add_pool\n","\n","from torch_geometric.transforms import AddLaplacianEigenvectorPE\n","import torch_geometric\n","\n","import torch.optim as optim\n","\n","from torch_geometric.datasets import ZINC\n","from torch_geometric.loader import DataLoader\n","\n","import torch.optim as optim\n","from torch_geometric.data import DataLoader\n","from sklearn.metrics import mean_squared_error\n","\n","from torch_geometric.transforms import AddRandomWalkPE\n","\n","import torch.nn.functional as F"]},{"cell_type":"markdown","source":["# MODEL:"],"metadata":{"id":"nxbRfIBwj8v2"}},{"cell_type":"code","source":["class MLPBlock(nn.Module):\n","    def __init__(self, in_channels, hidden_channels):\n","        super(MLPBlock, self).__init__()\n","        self.fc1 = nn.Linear(in_channels, hidden_channels)\n","        self.fc2 = nn.Linear(hidden_channels, hidden_channels)\n","\n","    def forward(self, x):\n","        x = x.float()  # Ensure the input is float before passing it to the linear layer\n","        x = F.relu(self.fc1(x))  # Apply ReLU activation after the first linear layer\n","        x = self.fc2(x)  # The second layer keeps the number of features as hidden_channels\n","        return x\n"],"metadata":{"id":"WLjIZKJZqrk5","executionInfo":{"status":"ok","timestamp":1731744987215,"user_tz":-120,"elapsed":1,"user":{"displayName":"שחר כהן","userId":"02544236883128860612"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["class GraphGPSModel(nn.Module):\n","\n","    def __init__(self, input_dim, hidden_dim, output_dim, pe_in_dim, pe_out_dim, num_layers):\n","        super(GraphGPSModel, self).__init__()\n","\n","        # MLP layers\n","        self.mlp1 = MLPBlock(input_dim + pe_out_dim, hidden_dim)\n","\n","        # Create MLP layers for GINEConv GPSConv layers\n","        self.mlps = nn.ModuleList([\n","            nn.Sequential(\n","                nn.Linear(hidden_dim, hidden_dim),\n","                nn.ReLU(),\n","                nn.Linear(hidden_dim, hidden_dim)\n","            )\n","            for _ in range(num_layers)\n","        ])\n","\n","        # Create GPSConv layers\n","        self.gps_layers = nn.ModuleList([\n","            GPSConv(\n","                hidden_dim,\n","                conv=GINEConv(self.mlps[i], eps=0.0, train_eps=False, edge_dim=3),\n","                heads=4,\n","                attn_kwargs={'dropout': 0.5}\n","            )\n","            for i in range(num_layers)\n","        ])\n","\n","        # Final fully connected layer\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","\n","        # PE layers\n","        self.bn_pe = nn.BatchNorm1d(pe_in_dim)\n","        self.fc_pe = nn.Linear(pe_in_dim, pe_out_dim)\n","\n","\n","\n","    def forward(self, data):\n","\n","        x, edge_index, batch, pe, edge_attr = (\n","            data.x,\n","            data.edge_index,\n","            data.batch,\n","            data.random_walk_pe,\n","            data.edge_attr\n","        )\n","\n","        # Transform edge attributes\n","        dummy_tensor = torch.zeros(edge_attr.size(0), 3, device=edge_attr.device)  # Change size to 3 for the new dummy\n","        dummy_tensor[edge_attr == 1, 0] = 1  # Keep the condition for edge_attr == 1\n","        dummy_tensor[edge_attr == 2, 1] = 1  # Keep the condition for edge_attr == 2\n","        dummy_tensor[edge_attr == 3, 2] = 1  # New condition for edge_attr == 3\n","        edge_attr = dummy_tensor\n","\n","\n","        # Process positional encodings (PE)\n","        pe = self.bn_pe(pe)\n","        pe = self.fc_pe(pe)\n","\n","        # Concatenate PE to node features\n","        x = torch.cat([x, pe], dim=1)\n","\n","        # Initial MLP processing\n","        x = self.mlp1(x)\n","\n","        # Sequentially apply GPSConv layers\n","        for gps_layer in self.gps_layers:\n","            x = gps_layer(x, edge_index, batch=batch, edge_attr=edge_attr)\n","\n","        # Global pooling to aggregate node features into graph features\n","        x = global_add_pool(x, batch)\n","\n","        # Final classification layer\n","        x = self.fc(x)\n","        return x\n"],"metadata":{"id":"BRpsMkmaMPrX","executionInfo":{"status":"ok","timestamp":1731747947503,"user_tz":-120,"elapsed":254,"user":{"displayName":"שחר כהן","userId":"02544236883128860612"}}},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":["# Load ZINC and add PE:"],"metadata":{"id":"dnFakKjoG7eh"}},{"cell_type":"code","source":["# Load the ZINC dataset\n","transform = AddRandomWalkPE(walk_length=20)\n","\n","# Load the ZINC dataset with predefined splits\n","train_dataset = ZINC(root='./data', subset=True, split='train', transform=transform)\n","val_dataset = ZINC(root='./data', subset=True, split='val', transform=transform)\n","test_dataset = ZINC(root='./data', subset=True, split='test', transform=transform)\n","\n","# Create DataLoaders for batching\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ONAcZhFhkXwC","executionInfo":{"status":"ok","timestamp":1731746295825,"user_tz":-120,"elapsed":70740,"user":{"displayName":"שחר כהן","userId":"02544236883128860612"}},"outputId":"fc46ffbd-f8d0-4715-c829-bb5981774e18"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading https://www.dropbox.com/s/feo9qle74kg48gy/molecules.zip?dl=1\n","Extracting data/molecules.zip\n","Downloading https://raw.githubusercontent.com/graphdeeplearning/benchmarking-gnns/master/data/molecules/train.index\n","Downloading https://raw.githubusercontent.com/graphdeeplearning/benchmarking-gnns/master/data/molecules/val.index\n","Downloading https://raw.githubusercontent.com/graphdeeplearning/benchmarking-gnns/master/data/molecules/test.index\n","Processing...\n","Processing train dataset: 100%|██████████| 10000/10000 [00:00<00:00, 12798.26it/s]\n","Processing val dataset: 100%|██████████| 1000/1000 [00:00<00:00, 3800.26it/s]\n","Processing test dataset: 100%|██████████| 1000/1000 [00:00<00:00, 8769.89it/s]\n","Done!\n","/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n","  warnings.warn(out)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"gXhGmtQWWjxo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Some tests that can be deleted before submission:"],"metadata":{"id":"bGaBqoUKWkDV"}},{"cell_type":"code","source":["\n","# Example of a data sample from the training set\n","data = train_dataset[10]\n","print(f'Training Node feature shape: {data.x.shape}, Edge index shape: {data.edge_index.shape}')\n","\n","# Example of a data sample from the testing set\n","test_data = test_dataset[0]\n","print(f'Testing Node feature shape: {test_data.x.shape}, Edge index shape: {test_data.edge_index.shape}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yWcjAwlwHmID","executionInfo":{"status":"ok","timestamp":1731746587946,"user_tz":-120,"elapsed":270,"user":{"displayName":"שחר כהן","userId":"02544236883128860612"}},"outputId":"b67e0478-e293-4b08-ecf2-952278dbb2a0"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Node feature shape: torch.Size([23, 1]), Edge index shape: torch.Size([2, 48])\n","Testing Node feature shape: torch.Size([16, 1]), Edge index shape: torch.Size([2, 34])\n"]}]},{"cell_type":"code","source":["data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hufdXAH5ojTx","executionInfo":{"status":"ok","timestamp":1731748619130,"user_tz":-120,"elapsed":271,"user":{"displayName":"שחר כהן","userId":"02544236883128860612"}},"outputId":"dd36f423-c3e8-41e9-9fbf-9e970ec97459"},"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Data(x=[18, 1], edge_index=[2, 38], edge_attr=[38], y=[1], random_walk_pe=[18, 20])"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["from collections import Counter\n","\n","# Initialize a Counter to aggregate edge attributes across the entire dataset\n","total_edge_attr_counts = Counter()\n","\n","# Iterate over the training dataset\n","for data in train_dataset:\n","    # Convert edge_attr tensor to a list and update the Counter\n","    total_edge_attr_counts.update(data.edge_attr.tolist())\n","\n","# Print the aggregated counts\n","print(total_edge_attr_counts)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7k0l1zKBItZe","executionInfo":{"status":"ok","timestamp":1731746663238,"user_tz":-120,"elapsed":9002,"user":{"displayName":"שחר כהן","userId":"02544236883128860612"}},"outputId":"312201da-543e-49eb-99fd-19269d440cb6"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Counter({1: 370120, 2: 127096, 3: 1342})\n"]}]},{"cell_type":"markdown","source":["# Training"],"metadata":{"id":"NkE9eOV5FwFq"}},{"cell_type":"code","source":["# Training loop\n","def train():\n","    model.train()\n","    total_loss = 0\n","    for data in train_loader:\n","        optimizer.zero_grad()\n","\n","        # Move data to the same device as the model\n","        data = data.to(device)\n","\n","        # Forward pass\n","        output = model(data)\n","\n","        # Get the target values (penalized logP)\n","        y = data.y.view(-1, 1).to(device)  # Ensure target is on the same device as the model\n","\n","        # Compute the loss\n","        loss = criterion(output, y)\n","        loss.backward()\n","\n","        # Optimization step\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","\n","    return total_loss / len(train_loader)\n","\n","\n","# Define a function to evaluate the model on a given dataset\n","def evaluate(loader):\n","    model.eval()\n","    total_loss = 0\n","    with torch.no_grad():  # Disable gradient computation for evaluation\n","        for data in loader:\n","            data = data.to(device)\n","            output = model(data)\n","            y = data.y.view(-1, 1).to(device)\n","            loss = criterion(output, y)\n","            total_loss += loss.item()\n","    return total_loss / len(loader)\n"],"metadata":{"id":"CER8ljDTmTPT","executionInfo":{"status":"ok","timestamp":1731747951529,"user_tz":-120,"elapsed":273,"user":{"displayName":"שחר כהן","userId":"02544236883128860612"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["num_layers = 10\n","input_dim = train_dataset.num_features\n","hidden_dim = 64\n","output_dim = 1\n","pe_in_dim = 20\n","pe_out_dim = 28\n","\n","weight_decay = 1e-5\n","lr = 0.001\n","epochs_num = 250"],"metadata":{"id":"Ob4fyi6lM3Id","executionInfo":{"status":"ok","timestamp":1731752373735,"user_tz":-120,"elapsed":283,"user":{"displayName":"שחר כהן","userId":"02544236883128860612"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["# Define the model\n","\n","model = GraphGPSModel(input_dim=input_dim, hidden_dim=hidden_dim,  output_dim=output_dim, pe_in_dim=pe_in_dim, pe_out_dim=pe_out_dim, num_layers=num_layers)\n","optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)\n","\n","# Loss function\n","criterion = nn.MSELoss()\n","\n","# Initialize variables to track the best model\n","best_val_loss = float('inf')\n","best_model = None\n","\n","# Training the model for epochs_num:\n","for epoch in range(epochs_num):\n","    # Train the model for one epoch\n","    train_loss = train()\n","\n","    # Evaluate the model on the validation set\n","    val_loss = evaluate(val_loader)\n","\n","    print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n","\n","    # Check if this is the best validation loss we've seen\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        # Save a copy of the best model\n","        best_model = model.state_dict()  # No need for deepcopy\n","        print(f'New best model saved at epoch {epoch+1} with Validation Loss: {val_loss:.4f}')\n","\n","# After training, you can save the best model to disk\n","torch.save(best_model, 'best_model_ZINC.pth')\n","print(\"Best model saved to 'best_model_ZINC.pth'.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Kl4B0v2LOCe","executionInfo":{"status":"ok","timestamp":1731758471023,"user_tz":-120,"elapsed":6093342,"user":{"displayName":"שחר כהן","userId":"02544236883128860612"}},"outputId":"326a3964-cd34-4f74-ea51-2dbda97ef75a"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Train Loss: 3.6688, Validation Loss: 1.7366\n","New best model saved at epoch 1 with Validation Loss: 1.7366\n","Epoch 2, Train Loss: 1.4720, Validation Loss: 1.5853\n","New best model saved at epoch 2 with Validation Loss: 1.5853\n","Epoch 3, Train Loss: 1.2599, Validation Loss: 1.9845\n","Epoch 4, Train Loss: 1.1281, Validation Loss: 1.1673\n","New best model saved at epoch 4 with Validation Loss: 1.1673\n","Epoch 5, Train Loss: 0.9987, Validation Loss: 1.1917\n","Epoch 6, Train Loss: 0.9766, Validation Loss: 0.9305\n","New best model saved at epoch 6 with Validation Loss: 0.9305\n","Epoch 7, Train Loss: 0.9103, Validation Loss: 1.0626\n","Epoch 8, Train Loss: 0.9221, Validation Loss: 1.1310\n","Epoch 9, Train Loss: 0.8731, Validation Loss: 1.1618\n","Epoch 10, Train Loss: 0.9117, Validation Loss: 0.8711\n","New best model saved at epoch 10 with Validation Loss: 0.8711\n","Epoch 11, Train Loss: 0.7969, Validation Loss: 0.7376\n","New best model saved at epoch 11 with Validation Loss: 0.7376\n","Epoch 12, Train Loss: 0.8817, Validation Loss: 1.0232\n","Epoch 13, Train Loss: 0.8552, Validation Loss: 0.8076\n","Epoch 14, Train Loss: 0.8156, Validation Loss: 1.2645\n","Epoch 15, Train Loss: 0.8679, Validation Loss: 0.9235\n","Epoch 16, Train Loss: 0.8133, Validation Loss: 1.6179\n","Epoch 17, Train Loss: 0.8435, Validation Loss: 1.2008\n","Epoch 18, Train Loss: 0.8832, Validation Loss: 0.9005\n","Epoch 19, Train Loss: 0.8108, Validation Loss: 0.8212\n","Epoch 20, Train Loss: 0.8184, Validation Loss: 0.7487\n","Epoch 21, Train Loss: 0.8351, Validation Loss: 1.0194\n","Epoch 22, Train Loss: 0.9594, Validation Loss: 1.0827\n","Epoch 23, Train Loss: 0.8065, Validation Loss: 0.8669\n","Epoch 24, Train Loss: 0.9798, Validation Loss: 1.1227\n","Epoch 25, Train Loss: 0.9470, Validation Loss: 0.7498\n","Epoch 26, Train Loss: 0.7866, Validation Loss: 0.8918\n","Epoch 27, Train Loss: 0.7418, Validation Loss: 1.0116\n","Epoch 28, Train Loss: 0.7657, Validation Loss: 2.6569\n","Epoch 29, Train Loss: 0.8418, Validation Loss: 1.2417\n","Epoch 30, Train Loss: 0.8069, Validation Loss: 0.9145\n","Epoch 31, Train Loss: 0.6848, Validation Loss: 0.7577\n","Epoch 32, Train Loss: 0.6930, Validation Loss: 0.6980\n","New best model saved at epoch 32 with Validation Loss: 0.6980\n","Epoch 33, Train Loss: 0.7624, Validation Loss: 0.8725\n","Epoch 34, Train Loss: 0.7394, Validation Loss: 1.0530\n","Epoch 35, Train Loss: 1.0301, Validation Loss: 0.9411\n","Epoch 36, Train Loss: 0.8874, Validation Loss: 0.8019\n","Epoch 37, Train Loss: 0.7668, Validation Loss: 0.8051\n","Epoch 38, Train Loss: 0.6727, Validation Loss: 0.8318\n","Epoch 39, Train Loss: 0.8275, Validation Loss: 1.0788\n","Epoch 40, Train Loss: 0.8622, Validation Loss: 0.9606\n","Epoch 41, Train Loss: 0.7933, Validation Loss: 6.4675\n","Epoch 42, Train Loss: 0.7415, Validation Loss: 0.7064\n","Epoch 43, Train Loss: 0.7059, Validation Loss: 0.7499\n","Epoch 44, Train Loss: 1.0238, Validation Loss: 1.7728\n","Epoch 45, Train Loss: 0.9689, Validation Loss: 1.2494\n","Epoch 46, Train Loss: 0.8356, Validation Loss: 0.8683\n","Epoch 47, Train Loss: 0.8915, Validation Loss: 1.4411\n","Epoch 48, Train Loss: 0.8623, Validation Loss: 0.9588\n","Epoch 49, Train Loss: 0.8112, Validation Loss: 0.7236\n","Epoch 50, Train Loss: 1.0571, Validation Loss: 1.0439\n","Epoch 51, Train Loss: 0.8198, Validation Loss: 0.8410\n","Epoch 52, Train Loss: 0.7499, Validation Loss: 0.8692\n","Epoch 53, Train Loss: 0.9496, Validation Loss: 1.5824\n","Epoch 54, Train Loss: 0.9630, Validation Loss: 0.7965\n","Epoch 55, Train Loss: 0.8507, Validation Loss: 0.7603\n","Epoch 56, Train Loss: 0.7662, Validation Loss: 0.8247\n","Epoch 57, Train Loss: 1.0648, Validation Loss: 0.9349\n","Epoch 58, Train Loss: 0.8528, Validation Loss: 0.8417\n","Epoch 59, Train Loss: 0.8327, Validation Loss: 9.2329\n","Epoch 60, Train Loss: 0.8011, Validation Loss: 0.8775\n","Epoch 61, Train Loss: 0.7821, Validation Loss: 1.3243\n","Epoch 62, Train Loss: 0.9168, Validation Loss: 0.7737\n","Epoch 63, Train Loss: 0.7893, Validation Loss: 0.7357\n","Epoch 64, Train Loss: 0.8365, Validation Loss: 0.8224\n","Epoch 65, Train Loss: 0.7297, Validation Loss: 0.6970\n","New best model saved at epoch 65 with Validation Loss: 0.6970\n","Epoch 66, Train Loss: 0.9457, Validation Loss: 0.8156\n","Epoch 67, Train Loss: 0.6998, Validation Loss: 10.0287\n","Epoch 68, Train Loss: 0.7356, Validation Loss: 0.7981\n","Epoch 69, Train Loss: 0.6826, Validation Loss: 0.8096\n","Epoch 70, Train Loss: 1.7085, Validation Loss: 1.3754\n","Epoch 71, Train Loss: 1.2663, Validation Loss: 1.0620\n","Epoch 72, Train Loss: 0.9574, Validation Loss: 1.0834\n","Epoch 73, Train Loss: 0.9182, Validation Loss: 0.9265\n","Epoch 74, Train Loss: 0.8892, Validation Loss: 0.8334\n","Epoch 75, Train Loss: 0.8459, Validation Loss: 0.9295\n","Epoch 76, Train Loss: 0.8579, Validation Loss: 0.8029\n","Epoch 77, Train Loss: 0.8560, Validation Loss: 0.9029\n","Epoch 78, Train Loss: 0.8101, Validation Loss: 0.7183\n","Epoch 79, Train Loss: 0.7852, Validation Loss: 0.8205\n","Epoch 80, Train Loss: 0.8057, Validation Loss: 0.7188\n","Epoch 81, Train Loss: 0.8302, Validation Loss: 0.8573\n","Epoch 82, Train Loss: 0.8467, Validation Loss: 0.9887\n","Epoch 83, Train Loss: 0.8025, Validation Loss: 0.8379\n","Epoch 84, Train Loss: 0.7628, Validation Loss: 0.7345\n","Epoch 85, Train Loss: 0.8672, Validation Loss: 0.9876\n","Epoch 86, Train Loss: 1.0555, Validation Loss: 1.1524\n","Epoch 87, Train Loss: 1.1664, Validation Loss: 1.0006\n","Epoch 88, Train Loss: 1.1526, Validation Loss: 0.9708\n","Epoch 89, Train Loss: 1.0919, Validation Loss: 0.8853\n","Epoch 90, Train Loss: 0.8101, Validation Loss: 0.8168\n","Epoch 91, Train Loss: 0.7795, Validation Loss: 0.7450\n","Epoch 92, Train Loss: 0.7710, Validation Loss: 0.6796\n","New best model saved at epoch 92 with Validation Loss: 0.6796\n","Epoch 93, Train Loss: 0.7583, Validation Loss: 0.7087\n","Epoch 94, Train Loss: 0.7468, Validation Loss: 0.7137\n","Epoch 95, Train Loss: 0.7459, Validation Loss: 0.8894\n","Epoch 96, Train Loss: 0.7920, Validation Loss: 0.7547\n","Epoch 97, Train Loss: 0.7548, Validation Loss: 0.8243\n","Epoch 98, Train Loss: 0.7556, Validation Loss: 0.8078\n","Epoch 99, Train Loss: 0.7577, Validation Loss: 1.0636\n","Epoch 100, Train Loss: 0.8201, Validation Loss: 0.7657\n","Epoch 101, Train Loss: 0.7626, Validation Loss: 0.7861\n","Epoch 102, Train Loss: 0.7386, Validation Loss: 0.6692\n","New best model saved at epoch 102 with Validation Loss: 0.6692\n","Epoch 103, Train Loss: 0.6903, Validation Loss: 0.6701\n","Epoch 104, Train Loss: 0.7253, Validation Loss: 0.6104\n","New best model saved at epoch 104 with Validation Loss: 0.6104\n","Epoch 105, Train Loss: 0.7067, Validation Loss: 0.6770\n","Epoch 106, Train Loss: 0.7337, Validation Loss: 0.7189\n","Epoch 107, Train Loss: 0.7236, Validation Loss: 0.7071\n","Epoch 108, Train Loss: 0.7152, Validation Loss: 0.7473\n","Epoch 109, Train Loss: 0.6574, Validation Loss: 0.7723\n","Epoch 110, Train Loss: 0.6623, Validation Loss: 0.8328\n","Epoch 111, Train Loss: 0.7717, Validation Loss: 0.8245\n","Epoch 112, Train Loss: 0.7529, Validation Loss: 0.7331\n","Epoch 113, Train Loss: 0.6887, Validation Loss: 0.7463\n","Epoch 114, Train Loss: 0.8326, Validation Loss: 0.8651\n","Epoch 115, Train Loss: 0.8256, Validation Loss: 0.7288\n","Epoch 116, Train Loss: 0.6973, Validation Loss: 0.7503\n","Epoch 117, Train Loss: 0.7264, Validation Loss: 0.6707\n","Epoch 118, Train Loss: 0.7147, Validation Loss: 0.7033\n","Epoch 119, Train Loss: 0.6699, Validation Loss: 0.7964\n","Epoch 120, Train Loss: 0.7365, Validation Loss: 0.8563\n","Epoch 121, Train Loss: 0.6643, Validation Loss: 0.6940\n","Epoch 122, Train Loss: 0.6372, Validation Loss: 0.6832\n","Epoch 123, Train Loss: 0.5812, Validation Loss: 0.6832\n","Epoch 124, Train Loss: 0.7338, Validation Loss: 0.6227\n","Epoch 125, Train Loss: 0.7099, Validation Loss: 0.7153\n","Epoch 126, Train Loss: 0.6829, Validation Loss: 0.6961\n","Epoch 127, Train Loss: 0.6827, Validation Loss: 0.6618\n","Epoch 128, Train Loss: 0.6778, Validation Loss: 0.6402\n","Epoch 129, Train Loss: 0.6285, Validation Loss: 1.0096\n","Epoch 130, Train Loss: 0.6211, Validation Loss: 0.8788\n","Epoch 131, Train Loss: 0.6426, Validation Loss: 0.8325\n","Epoch 132, Train Loss: 0.8694, Validation Loss: 0.9347\n","Epoch 133, Train Loss: 0.6595, Validation Loss: 0.7977\n","Epoch 134, Train Loss: 0.6087, Validation Loss: 0.9363\n","Epoch 135, Train Loss: 0.5659, Validation Loss: 0.5982\n","New best model saved at epoch 135 with Validation Loss: 0.5982\n","Epoch 136, Train Loss: 0.5911, Validation Loss: 3.0750\n","Epoch 137, Train Loss: 0.7177, Validation Loss: 0.9358\n","Epoch 138, Train Loss: 0.5786, Validation Loss: 0.6885\n","Epoch 139, Train Loss: 0.5565, Validation Loss: 0.6379\n","Epoch 140, Train Loss: 0.5867, Validation Loss: 0.6050\n","Epoch 141, Train Loss: 0.5667, Validation Loss: 0.6387\n","Epoch 142, Train Loss: 0.8616, Validation Loss: 0.5792\n","New best model saved at epoch 142 with Validation Loss: 0.5792\n","Epoch 143, Train Loss: 0.7965, Validation Loss: 0.8108\n","Epoch 144, Train Loss: 0.6984, Validation Loss: 0.6773\n","Epoch 145, Train Loss: 0.5165, Validation Loss: 0.6307\n","Epoch 146, Train Loss: 0.5366, Validation Loss: 0.6952\n","Epoch 147, Train Loss: 0.6534, Validation Loss: 0.4990\n","New best model saved at epoch 147 with Validation Loss: 0.4990\n","Epoch 148, Train Loss: 0.7111, Validation Loss: 1.1334\n","Epoch 149, Train Loss: 1.0899, Validation Loss: 0.7600\n","Epoch 150, Train Loss: 0.6629, Validation Loss: 0.6692\n","Epoch 151, Train Loss: 0.6877, Validation Loss: 0.7088\n","Epoch 152, Train Loss: 0.6226, Validation Loss: 0.9248\n","Epoch 153, Train Loss: 0.6440, Validation Loss: 0.8082\n","Epoch 154, Train Loss: 0.6254, Validation Loss: 0.6932\n","Epoch 155, Train Loss: 0.5936, Validation Loss: 0.7830\n","Epoch 156, Train Loss: 0.6630, Validation Loss: 0.6718\n","Epoch 157, Train Loss: 0.5588, Validation Loss: 0.6170\n","Epoch 158, Train Loss: 0.4944, Validation Loss: 1.0124\n","Epoch 159, Train Loss: 0.5844, Validation Loss: 1.0061\n","Epoch 160, Train Loss: 0.5032, Validation Loss: 1.8295\n","Epoch 161, Train Loss: 0.6768, Validation Loss: 0.9157\n","Epoch 162, Train Loss: 0.6756, Validation Loss: 0.8894\n","Epoch 163, Train Loss: 0.6440, Validation Loss: 0.6691\n","Epoch 164, Train Loss: 0.4575, Validation Loss: 0.5420\n","Epoch 165, Train Loss: 0.4138, Validation Loss: 0.5844\n","Epoch 166, Train Loss: 0.3668, Validation Loss: 0.6906\n","Epoch 167, Train Loss: 0.3779, Validation Loss: 0.6977\n","Epoch 168, Train Loss: 0.6136, Validation Loss: 0.8038\n","Epoch 169, Train Loss: 0.6656, Validation Loss: 1.0675\n","Epoch 170, Train Loss: 0.8203, Validation Loss: 0.6731\n","Epoch 171, Train Loss: 0.6764, Validation Loss: 0.7890\n","Epoch 172, Train Loss: 0.6579, Validation Loss: 0.6455\n","Epoch 173, Train Loss: 0.5593, Validation Loss: 1.2216\n","Epoch 174, Train Loss: 0.6099, Validation Loss: 0.8603\n","Epoch 175, Train Loss: 0.4337, Validation Loss: 0.5878\n","Epoch 176, Train Loss: 0.3844, Validation Loss: 0.6310\n","Epoch 177, Train Loss: 0.3440, Validation Loss: 0.9980\n","Epoch 178, Train Loss: 0.3634, Validation Loss: 0.6063\n","Epoch 179, Train Loss: 0.3836, Validation Loss: 0.6352\n","Epoch 180, Train Loss: 0.3813, Validation Loss: 0.7789\n","Epoch 181, Train Loss: 0.4911, Validation Loss: 0.5551\n","Epoch 182, Train Loss: 0.6261, Validation Loss: 0.7137\n","Epoch 183, Train Loss: 0.8797, Validation Loss: 0.9660\n","Epoch 184, Train Loss: 0.7171, Validation Loss: 0.7515\n","Epoch 185, Train Loss: 0.7542, Validation Loss: 0.7633\n","Epoch 186, Train Loss: 0.7346, Validation Loss: 0.7692\n","Epoch 187, Train Loss: 0.5023, Validation Loss: 0.6742\n","Epoch 188, Train Loss: 0.5570, Validation Loss: 0.6249\n","Epoch 189, Train Loss: 0.4349, Validation Loss: 0.7345\n","Epoch 190, Train Loss: 0.5287, Validation Loss: 0.5803\n","Epoch 191, Train Loss: 0.3646, Validation Loss: 1.0940\n","Epoch 192, Train Loss: 0.3202, Validation Loss: 0.4760\n","New best model saved at epoch 192 with Validation Loss: 0.4760\n","Epoch 193, Train Loss: 0.3777, Validation Loss: 0.9880\n","Epoch 194, Train Loss: 0.4756, Validation Loss: 0.7933\n","Epoch 195, Train Loss: 0.3922, Validation Loss: 0.7487\n","Epoch 196, Train Loss: 0.4744, Validation Loss: 0.6168\n","Epoch 197, Train Loss: 0.4345, Validation Loss: 0.4715\n","New best model saved at epoch 197 with Validation Loss: 0.4715\n","Epoch 198, Train Loss: 0.3538, Validation Loss: 0.7766\n","Epoch 199, Train Loss: 0.5953, Validation Loss: 0.6782\n","Epoch 200, Train Loss: 0.3505, Validation Loss: 0.5234\n","Epoch 201, Train Loss: 0.3207, Validation Loss: 0.4761\n","Epoch 202, Train Loss: 0.3022, Validation Loss: 0.9039\n","Epoch 203, Train Loss: 0.3493, Validation Loss: 0.4545\n","New best model saved at epoch 203 with Validation Loss: 0.4545\n","Epoch 204, Train Loss: 0.3317, Validation Loss: 0.5739\n","Epoch 205, Train Loss: 0.2785, Validation Loss: 0.6557\n","Epoch 206, Train Loss: 0.3663, Validation Loss: 0.6312\n","Epoch 207, Train Loss: 0.5367, Validation Loss: 0.5631\n","Epoch 208, Train Loss: 0.4251, Validation Loss: 0.5367\n","Epoch 209, Train Loss: 0.4001, Validation Loss: 0.6170\n","Epoch 210, Train Loss: 0.5483, Validation Loss: 0.7341\n","Epoch 211, Train Loss: 0.5581, Validation Loss: 0.6914\n","Epoch 212, Train Loss: 0.5518, Validation Loss: 0.7553\n","Epoch 213, Train Loss: 0.4553, Validation Loss: 0.7385\n","Epoch 214, Train Loss: 0.3659, Validation Loss: 0.5595\n","Epoch 215, Train Loss: 0.4139, Validation Loss: 0.5922\n","Epoch 216, Train Loss: 0.6378, Validation Loss: 0.8064\n","Epoch 217, Train Loss: 0.6535, Validation Loss: 0.6817\n","Epoch 218, Train Loss: 0.5329, Validation Loss: 0.8460\n","Epoch 219, Train Loss: 0.5801, Validation Loss: 0.7002\n","Epoch 220, Train Loss: 0.5467, Validation Loss: 0.7306\n","Epoch 221, Train Loss: 0.5829, Validation Loss: 1.0039\n","Epoch 222, Train Loss: 0.5518, Validation Loss: 0.7048\n","Epoch 223, Train Loss: 0.4584, Validation Loss: 0.5741\n","Epoch 224, Train Loss: 0.3140, Validation Loss: 0.5819\n","Epoch 225, Train Loss: 0.2907, Validation Loss: 0.6232\n","Epoch 226, Train Loss: 0.3075, Validation Loss: 2.4719\n","Epoch 227, Train Loss: 0.4986, Validation Loss: 0.6816\n","Epoch 228, Train Loss: 0.3777, Validation Loss: 0.8963\n","Epoch 229, Train Loss: 0.5004, Validation Loss: 0.6598\n","Epoch 230, Train Loss: 0.4869, Validation Loss: 0.5292\n","Epoch 231, Train Loss: 0.3039, Validation Loss: 0.6309\n","Epoch 232, Train Loss: 0.3542, Validation Loss: 0.5924\n","Epoch 233, Train Loss: 0.3058, Validation Loss: 0.4771\n","Epoch 234, Train Loss: 0.2871, Validation Loss: 0.5194\n","Epoch 235, Train Loss: 0.2634, Validation Loss: 0.4505\n","New best model saved at epoch 235 with Validation Loss: 0.4505\n","Epoch 236, Train Loss: 0.2524, Validation Loss: 0.5387\n","Epoch 237, Train Loss: 0.2362, Validation Loss: 0.5110\n","Epoch 238, Train Loss: 0.2360, Validation Loss: 0.3979\n","New best model saved at epoch 238 with Validation Loss: 0.3979\n","Epoch 239, Train Loss: 0.2813, Validation Loss: 0.5372\n","Epoch 240, Train Loss: 0.3802, Validation Loss: 0.6727\n","Epoch 241, Train Loss: 0.3784, Validation Loss: 0.8714\n","Epoch 242, Train Loss: 0.4311, Validation Loss: 0.6013\n","Epoch 243, Train Loss: 0.6435, Validation Loss: 0.7369\n","Epoch 244, Train Loss: 0.4575, Validation Loss: 0.5548\n","Epoch 245, Train Loss: 0.3456, Validation Loss: 0.6623\n","Epoch 246, Train Loss: 0.3146, Validation Loss: 0.4442\n","Epoch 247, Train Loss: 0.3018, Validation Loss: 0.5214\n","Epoch 248, Train Loss: 0.3084, Validation Loss: 0.6683\n","Epoch 249, Train Loss: 0.4372, Validation Loss: 0.7768\n","Epoch 250, Train Loss: 0.5052, Validation Loss: 0.5755\n","Best model saved to 'best_model_ZINC.pth'.\n"]}]},{"cell_type":"markdown","source":["#Test Score:"],"metadata":{"id":"XPVdksrQPUVx"}},{"cell_type":"code","source":["def test_score():\n","    model.eval()  # Set the model to evaluation mode\n","    total_mae = 0.0\n","    num_batches = 0\n","\n","    with torch.no_grad():  # Disable gradient computation during evaluation\n","        for batch in test_loader:  # Assuming you have a DataLoader for your test set\n","            # Move batch data to the same device as the model\n","            data = batch.to(device)\n","\n","            # Forward pass (prediction)\n","            output = model(data)\n","\n","            # Ensure target is the correct shape\n","            target = data.y.view(-1, 1).to(device)  # Match output shape: [batch_size, 1]\n","\n","            # Compute Mean Absolute Error (MAE)\n","            mae_loss = F.l1_loss(output, target)\n","\n","            total_mae += mae_loss.item()\n","            num_batches += 1\n","\n","    # Return average MAE over all batches in the test set\n","    avg_mae = total_mae / num_batches\n","    return avg_mae\n","\n","\n","# Load the best model's state dictionary\n","model.load_state_dict(best_model)\n","model.to(device)  # Ensure the model is on the correct device (GPU or CPU)\n","\n","# Now you can evaluate the model on the test set\n","test_mae = test_score()\n","print(f\"Test MAE: {test_mae:.4f}\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QCv2x6QKmTQ-","executionInfo":{"status":"ok","timestamp":1731758485487,"user_tz":-120,"elapsed":1732,"user":{"displayName":"שחר כהן","userId":"02544236883128860612"}},"outputId":"4c85ac24-0a3e-4bab-ef4f-d18068fa24f8"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Test MAE: 0.2661\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"gpuType":"A100"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":0}