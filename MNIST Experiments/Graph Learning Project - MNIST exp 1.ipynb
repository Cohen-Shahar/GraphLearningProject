{"cells":[{"cell_type":"markdown","metadata":{"id":"XuXWJLEm2UWS"},"source":["# **Graph Learning Project - MNIST exp 1**"]},{"cell_type":"markdown","metadata":{"id":"8gzsP50bF6Gb"},"source":["By Shahar Cohen 205669260 & Alex petrunin 205782568"]},{"cell_type":"markdown","metadata":{"id":"67gOQITlCNQi"},"source":["# Installation"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":3619,"status":"ok","timestamp":1731828106328,"user":{"displayName":"שחר כהן","userId":"02544236883128860612"},"user_tz":-120},"id":"J_m9l6OYCQZP"},"outputs":[],"source":["!pip install -q torch-geometric"]},{"cell_type":"markdown","metadata":{"id":"9V_JqF8wNr1q"},"source":["# SETUP"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"PRfgbfTjCRD_","executionInfo":{"status":"ok","timestamp":1731828106328,"user_tz":-120,"elapsed":3,"user":{"displayName":"שחר כהן","userId":"02544236883128860612"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch_geometric.nn import GPSConv, GatedGraphConv, TransformerConv, GINEConv\n","from torch_geometric.data import Data\n","import torch.nn.functional as F\n","from torch_geometric.nn import global_mean_pool, global_add_pool\n","\n","from torch_geometric.transforms import AddLaplacianEigenvectorPE\n","import torch_geometric\n","\n","import torch.optim as optim\n","\n","from torch_geometric.datasets import ZINC\n","from torch_geometric.loader import DataLoader\n","\n","import torch.optim as optim\n","from torch_geometric.data import DataLoader\n","from sklearn.metrics import mean_squared_error\n","\n","from torch_geometric.datasets import MNISTSuperpixels"]},{"cell_type":"markdown","metadata":{"id":"IknO-zbNN4H-"},"source":["# MODEL"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"wxXYZk9FBgyx","executionInfo":{"status":"ok","timestamp":1731828106328,"user_tz":-120,"elapsed":2,"user":{"displayName":"שחר כהן","userId":"02544236883128860612"}}},"outputs":[],"source":["class MLPBlock(nn.Module):\n","    def __init__(self, in_channels, hidden_channels):\n","        super(MLPBlock, self).__init__()\n","        self.fc1 = nn.Linear(in_channels, hidden_channels)\n","        self.fc2 = nn.Linear(hidden_channels, hidden_channels)  # This should output 'hidden_channels'\n","\n","    def forward(self, x):\n","        x = x.float()  # Ensure the input is float before passing it to the linear layer\n","        x = F.relu(self.fc1(x))  # Apply ReLU activation after the first linear layer\n","        x = self.fc2(x)  # The second layer keeps the number of features as hidden_channels\n","        return x\n","\n","\n","class GraphGPSModel(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim, pe_dim):\n","        super(GraphGPSModel, self).__init__()\n","\n","        # MLP layers for each GPSConv layer\n","        self.mlp1 = MLPBlock(input_dim + pe_dim, hidden_dim)\n","\n","        # GPSConv layers\n","        self.gps1 = GPSConv(hidden_dim, conv=GatedGraphConv(hidden_dim, 2), heads=4, attn_kwargs={'dropout':0.5})\n","        self.gps2 = GPSConv(hidden_dim, conv=GatedGraphConv(hidden_dim, 2), heads=4, attn_kwargs={'dropout':0.5})\n","        self.gps3 = GPSConv(hidden_dim, conv=GatedGraphConv(hidden_dim, 2), heads=4, attn_kwargs={'dropout':0.5})\n","\n","        # Final classifier layer\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","\n","        # PE ####\n","        # MLP for PE\n","        self.mlp_pe = MLPBlock(pe_dim, pe_dim)\n","        #self.fc_pe = nn.Linear(pe_dim, pe_dim)\n","\n","        #######\n","\n","        self.softmax = nn.Softmax(dim=1)\n","\n","    def forward(self, data):\n","        x, edge_index, batch, pe, edge_attr = data.x, data.edge_index, data.batch, data.laplacian_eigenvector_pe, data.edge_attr\n","\n","        ##### this needs to change\n","        # PE linear layer\n","        pe = self.mlp_pe(pe)\n","        #pe = self.fc_pe(pe)\n","        #####\n","\n","        # Concatenate PE to x (along the feature dimension, axis=1)\n","        x = torch.cat([x, pe], dim=1)\n","\n","        # Pass through MLP blocks before GPSConv layers\n","        x = self.mlp1(x)\n","\n","        # Pass through gps layers\n","        x = self.gps1(x, edge_index, batch=batch)\n","        x = self.gps2(x, edge_index, batch=batch)\n","        x = self.gps3(x, edge_index, batch=batch)\n","\n","        # Global pooling\n","        x = global_mean_pool(x, batch)\n","\n","        # Final classification layer\n","        x = self.fc(x)\n","        return self.softmax(x)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"jcQdirAxrL1j"},"source":["#Load MNIST and add PE"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":1290,"status":"ok","timestamp":1731828107616,"user":{"displayName":"שחר כהן","userId":"02544236883128860612"},"user_tz":-120},"id":"i97GDQ8OBg0-"},"outputs":[],"source":["# PE\n","transform_le = AddLaplacianEigenvectorPE(k=8)\n","\n","# Load the MNISTSuperpixels dataset\n","root_dir = './data/MNISTSuperpixels'\n","train_dataset = MNISTSuperpixels(root=root_dir, train=True, transform=transform_le)\n","test_dataset = MNISTSuperpixels(root=root_dir, train=False, transform=transform_le)\n","\n","train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1731828107616,"user":{"displayName":"שחר כהן","userId":"02544236883128860612"},"user_tz":-120},"id":"yCMJYhRDqtLY","outputId":"88a38cdc-331b-4158-cbcc-13e402194109"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training Node feature shape: torch.Size([75, 1]), Edge index shape: torch.Size([2, 1399])\n","Testing Node feature shape: torch.Size([75, 1]), Edge index shape: torch.Size([2, 1405])\n"]}],"source":["\n","# Example of a data sample from the training set\n","data = train_dataset[0]\n","print(f'Training Node feature shape: {data.x.shape}, Edge index shape: {data.edge_index.shape}')\n","\n","# Example of a data sample from the testing set\n","test_data = test_dataset[0]\n","print(f'Testing Node feature shape: {test_data.x.shape}, Edge index shape: {test_data.edge_index.shape}')\n"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1731828107616,"user":{"displayName":"שחר כהן","userId":"02544236883128860612"},"user_tz":-120},"id":"R16g3GuTDq8P","outputId":"0fd0b683-7529-47fc-8d8e-a5f850e5d588"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Data(x=[75, 1], edge_index=[2, 1399], y=[1], pos=[75, 2], laplacian_eigenvector_pe=[75, 8])"]},"metadata":{},"execution_count":16}],"source":["data"]},{"cell_type":"markdown","metadata":{"id":"-K24WZ9hrdT4"},"source":["#Training"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"RcuZj1THrgGd","executionInfo":{"status":"ok","timestamp":1731828107616,"user_tz":-120,"elapsed":2,"user":{"displayName":"שחר כהן","userId":"02544236883128860612"}}},"outputs":[],"source":["# Training loop\n","def train():\n","    model.train()\n","    total_loss = 0\n","    for data in train_loader:\n","        optimizer.zero_grad()\n","\n","        # Move data to the same device as the model\n","        data = data.to(device)\n","\n","        # Forward pass\n","        output = model(data)\n","\n","        # Get the target values\n","        y = data.y.view(-1, 1).to(device)\n","        y = y.squeeze()\n","        num_classes = output.size(1)\n","        y_one_hot = torch.zeros(y.size(0), num_classes, device='cuda')\n","        y_one_hot.scatter_(1, y.unsqueeze(1), 1)\n","\n","        # Compute the loss\n","        loss = criterion(output, y_one_hot)\n","        loss.backward()\n","\n","        # Optimization step\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","\n","    return total_loss / len(train_loader)\n","\n","\n","# Define a function to evaluate the model on a given dataset\n","def evaluate(loader):\n","    model.eval()\n","    total_loss = 0\n","    with torch.no_grad():  # Disable gradient computation for evaluation\n","        for data in loader:\n","            data = data.to(device)\n","            output = model(data)\n","            y = data.y.view(-1, 1).to(device)\n","            y = y.squeeze()\n","            num_classes = output.size(1)\n","            y_one_hot = torch.zeros(y.size(0), num_classes, device='cuda')\n","            y_one_hot.scatter_(1, y.unsqueeze(1), 1)\n","            loss = criterion(output, y_one_hot)\n","            total_loss += loss.item()\n","    return total_loss / len(loader)\n"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"WWEyryKNrlOH","executionInfo":{"status":"ok","timestamp":1731828107616,"user_tz":-120,"elapsed":1,"user":{"displayName":"שחר כהן","userId":"02544236883128860612"}}},"outputs":[],"source":["# num_layers = 3\n","input_dim = train_dataset.num_features\n","hidden_dim = 52\n","output_dim = 10\n","pe_dim = 8\n","\n","weight_decay = 1e-5\n","lr = 0.001\n","epochs_num = 10"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bH3wCS-RBg3K","executionInfo":{"status":"ok","timestamp":1731831437827,"user_tz":-120,"elapsed":3330212,"user":{"displayName":"שחר כהן","userId":"02544236883128860612"}},"outputId":"ca8880fc-a576-4b7a-dcdb-e0f18cad139f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Train Loss: 1.9715, Validation Loss: 2.1579\n","New best model saved at epoch 1 with Validation Loss: 2.1579\n","Epoch 2, Train Loss: 1.8282, Validation Loss: 1.8142\n","New best model saved at epoch 2 with Validation Loss: 1.8142\n","Epoch 3, Train Loss: 1.7943, Validation Loss: 1.7784\n","New best model saved at epoch 3 with Validation Loss: 1.7784\n","Epoch 4, Train Loss: 1.7893, Validation Loss: 1.7429\n","New best model saved at epoch 4 with Validation Loss: 1.7429\n","Epoch 5, Train Loss: 1.7807, Validation Loss: 1.8884\n","Epoch 6, Train Loss: 1.7823, Validation Loss: 1.7612\n","Epoch 7, Train Loss: 1.7874, Validation Loss: 1.8358\n","Epoch 8, Train Loss: 1.7870, Validation Loss: 1.7877\n","Epoch 9, Train Loss: 1.8075, Validation Loss: 1.7343\n","New best model saved at epoch 9 with Validation Loss: 1.7343\n","Epoch 10, Train Loss: 1.7879, Validation Loss: 1.9760\n","Best model saved to 'best_model_MNIST.pth'.\n"]}],"source":["# Define the model\n","\n","model = GraphGPSModel(input_dim=input_dim, hidden_dim=hidden_dim,  output_dim=output_dim, pe_dim=pe_dim)\n","optimizer = optim.Adam(model.parameters(), lr=lr)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)\n","\n","# Loss function\n","criterion = nn.CrossEntropyLoss()\n","\n","# Initialize variables to track the best model\n","best_val_loss = float('inf')\n","best_model = None\n","\n","# Training the model for epochs_num:\n","for epoch in range(epochs_num):\n","    # Train the model for one epoch\n","    train_loss = train()\n","\n","    # Evaluate the model on the validation set\n","    val_loss = evaluate(test_loader)\n","\n","    print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n","\n","    # Check if this is the best validation loss we've seen\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        # Save a copy of the best model\n","        best_model = model.state_dict()  # No need for deepcopy\n","        print(f'New best model saved at epoch {epoch+1} with Validation Loss: {val_loss:.4f}')\n","\n","# After training, you can save the best model to disk\n","torch.save(best_model, 'best_model_MNIST.pth')\n","print(\"Best model saved to 'best_model_MNIST.pth'.\")"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IHFvi6xdBg5U","outputId":"92e79a9d-a992-4e52-9436-f8419cf2db1c","executionInfo":{"status":"ok","timestamp":1731831478389,"user_tz":-120,"elapsed":40564,"user":{"displayName":"שחר כהן","userId":"02544236883128860612"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Final Test Accuracy: 48.23%\n"]}],"source":["def compute_accuracy(loader, model):\n","    model.eval()  # Set the model to evaluation mode\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation for evaluation\n","        for data in loader:\n","            data = data.to(device)\n","\n","            # Forward pass\n","            output = model(data)\n","\n","            # Get the predicted class (index with max probability)\n","            _, predicted = torch.max(output, 1)\n","\n","            # Get the true labels\n","            y = data.y.view(-1).to(device)\n","\n","            # Update correct predictions and total samples\n","            correct += (predicted == y).sum().item()\n","            total += y.size(0)\n","\n","    # Compute accuracy\n","    accuracy = 100 * correct / total\n","    return accuracy\n","\n","# Load the best model's state dictionary\n","model.load_state_dict(best_model)\n","model.to(device)  # Ensure the model is on the correct device (GPU or CPU)\n","\n","\n","# Compute and print the test accuracy after training\n","test_accuracy = compute_accuracy(test_loader, model)\n","print(f'Final Test Accuracy: {test_accuracy:.2f}%')"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[{"file_id":"1xQXVlK-CfZxyLG6gSleHOv0PMZmbdRDB","timestamp":1731685372048}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":0}